{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Copyright (c) 2022 Huawei Technologies Co., Ltd.<br>\n", "Licensed under CC BY-NC-SA 4.0 (Attribution-NonCommercial-ShareAlike 4.0 International) (the \"License\");<br>\n", "you may not use this file except in compliance with the License.<br>\n", "You may obtain a copy of the License at<br>\n", "<br>\n", "    https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode<br>\n", "<br>\n", "The code is released for academic research use only. For commercial use, please contact Huawei Technologies Co., Ltd.<br>\n", "Unless required by applicable law or agreed to in writing, software<br>\n", "distributed under the License is distributed on an \"AS IS\" BASIS,<br>\n", "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>\n", "See the License for the specific language governing permissions and<br>\n", "limitations under the License.<br>\n", "<br>\n", "This repository was forked from https://github.com/openai/guided-diffusion, which is under the MIT license"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Like image_sample.py, but use a noisy image classifier to guide the sampling<br>\n", "process towards more realistic images.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import argparse\n", "import torch as th\n", "import torch.nn.functional as F\n", "import time\n", "import conf_mgt\n", "from utils import yamlread\n", "from guided_diffusion import dist_util"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Workaround"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import ctypes\n", "    libgcc_s = ctypes.CDLL('libgcc_s.so.1')\n", "except:\n", "    pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from guided_diffusion.script_util import (\n", "    NUM_CLASSES,\n", "    model_and_diffusion_defaults,\n", "    classifier_defaults,\n", "    create_model_and_diffusion,\n", "    create_classifier,\n", "    select_args,\n", ")  # noqa: E402"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def toU8(sample):\n", "    if sample is None:\n", "        return sample\n", "    sample = ((sample + 1) * 127.5).clamp(0, 255).to(th.uint8)\n", "    sample = sample.permute(0, 2, 3, 1)\n", "    sample = sample.contiguous()\n", "    sample = sample.detach().cpu().numpy()\n", "    return sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(conf: conf_mgt.Default_Conf):\n", "    print(\"Start\", conf['name'])\n", "    device = dist_util.dev(conf.get('device'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    model, diffusion = create_model_and_diffusion(\n", "        **select_args(conf, model_and_diffusion_defaults().keys()), conf=conf\n", "    )\n", "    model.load_state_dict(\n", "        dist_util.load_state_dict(os.path.expanduser(\n", "            conf.model_path), map_location=\"cpu\")\n", "    )\n", "    model.to(device)\n", "    if conf.use_fp16:\n", "        model.convert_to_fp16()\n", "    model.eval()\n", "    show_progress = conf.show_progress\n", "    if conf.classifier_scale > 0 and conf.classifier_path:\n", "        print(\"loading classifier...\")\n", "        classifier = create_classifier(\n", "            **select_args(conf, classifier_defaults().keys()))\n", "        classifier.load_state_dict(\n", "            dist_util.load_state_dict(os.path.expanduser(\n", "                conf.classifier_path), map_location=\"cpu\")\n", "        )\n", "        classifier.to(device)\n", "        if conf.classifier_use_fp16:\n", "            classifier.convert_to_fp16()\n", "        classifier.eval()\n", "        def cond_fn(x, t, y=None, gt=None, **kwargs):\n", "            assert y is not None\n", "            with th.enable_grad():\n", "                x_in = x.detach().requires_grad_(True)\n", "                logits = classifier(x_in, t)\n", "                log_probs = F.log_softmax(logits, dim=-1)\n", "                selected = log_probs[range(len(logits)), y.view(-1)]\n", "                return th.autograd.grad(selected.sum(), x_in)[0] * conf.classifier_scale\n", "    else:\n", "        cond_fn = None\n", "    def model_fn(x, t, y=None, gt=None, **kwargs):\n", "        assert y is not None\n", "        return model(x, t, y if conf.class_cond else None, gt=gt)\n", "    print(\"sampling...\")\n", "    all_images = []\n", "    dset = 'eval'\n", "    eval_name = conf.get_default_eval_name()\n", "    dl = conf.get_dataloader(dset=dset, dsName=eval_name)\n", "    for batch in iter(dl):\n", "        for k in batch.keys():\n", "            if isinstance(batch[k], th.Tensor):\n", "                batch[k] = batch[k].to(device)\n", "        model_kwargs = {}\n", "        model_kwargs[\"gt\"] = batch['GT']\n", "        gt_keep_mask = batch.get('gt_keep_mask')\n", "        if gt_keep_mask is not None:\n", "            model_kwargs['gt_keep_mask'] = gt_keep_mask\n", "        batch_size = model_kwargs[\"gt\"].shape[0]\n", "        if conf.cond_y is not None:\n", "            classes = th.ones(batch_size, dtype=th.long, device=device)\n", "            model_kwargs[\"y\"] = classes * conf.cond_y\n", "        else:\n", "            classes = th.randint(\n", "                low=0, high=NUM_CLASSES, size=(batch_size,), device=device\n", "            )\n", "            model_kwargs[\"y\"] = classes\n", "        sample_fn = (\n", "            diffusion.p_sample_loop if not conf.use_ddim else diffusion.ddim_sample_loop\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        result = sample_fn(\n", "            model_fn,\n", "            (batch_size, 3, conf.image_size, conf.image_size),\n", "            clip_denoised=conf.clip_denoised,\n", "            model_kwargs=model_kwargs,\n", "            cond_fn=cond_fn,\n", "            device=device,\n", "            progress=show_progress,\n", "            return_all=True,\n", "            conf=conf\n", "        )\n", "        srs = toU8(result['sample'])\n", "        gts = toU8(result['gt'])\n", "        lrs = toU8(result.get('gt') * model_kwargs.get('gt_keep_mask') + (-1) *\n", "                   th.ones_like(result.get('gt')) * (1 - model_kwargs.get('gt_keep_mask')))\n", "        gt_keep_masks = toU8((model_kwargs.get('gt_keep_mask') * 2 - 1))\n", "        conf.eval_imswrite(\n", "            srs=srs, gts=gts, lrs=lrs, gt_keep_masks=gt_keep_masks,\n", "            img_names=batch['GT_name'], dset=dset, name=eval_name, verify_same=False)\n", "    print(\"sampling complete\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    parser = argparse.ArgumentParser()\n", "    parser.add_argument('--conf_path', type=str, required=False, default=None)\n", "    args = vars(parser.parse_args())\n", "    conf_arg = conf_mgt.conf_base.Default_Conf()\n", "    conf_arg.update(yamlread(args.get('conf_path')))\n", "    main(conf_arg)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}