{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Copyright (c) 2022 Huawei Technologies Co., Ltd.<br>\n", "Licensed under CC BY-NC-SA 4.0 (Attribution-NonCommercial-ShareAlike 4.0 International) (the \"License\");<br>\n", "you may not use this file except in compliance with the License.<br>\n", "You may obtain a copy of the License at<br>\n", "<br>\n", "    https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode<br>\n", "<br>\n", "The code is released for academic research use only. For commercial use, please contact Huawei Technologies Co., Ltd.<br>\n", "Unless required by applicable law or agreed to in writing, software<br>\n", "distributed under the License is distributed on an \"AS IS\" BASIS,<br>\n", "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>\n", "See the License for the specific language governing permissions and<br>\n", "limitations under the License.<br>\n", "<br>\n", "This repository was forked from https://github.com/openai/guided-diffusion, which is under the MIT license"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image\n", "import blobfile as bf\n", "import numpy as np\n", "from torch.utils.data import DataLoader, Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_data_yield(loader):\n", "    while True:\n", "        yield from loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_data_inpa(\n", "    *,\n", "    gt_path=None,\n", "    mask_path=None,\n", "    batch_size,\n", "    image_size,\n", "    class_cond=False,\n", "    deterministic=False,\n", "    random_crop=False,\n", "    random_flip=True,\n", "    return_dataloader=False,\n", "    return_dict=False,\n", "    max_len=None,\n", "    drop_last=True,\n", "    conf=None,\n", "    offset=0,\n", "    ** kwargs\n", "):\n", "    \"\"\"\n", "    For a dataset, create a generator over (images, kwargs) pairs.\n", "    Each images is an NCHW float tensor, and the kwargs dict contains zero or\n", "    more keys, each of which map to a batched Tensor of their own.\n", "    The kwargs dict can be used for class labels, in which case the key is \"y\"\n", "    and the values are integer tensors of class labels.\n", "    :param data_dir: a dataset directory.\n", "    :param batch_size: the batch size of each returned pair.\n", "    :param image_size: the size to which images are resized.\n", "    :param class_cond: if True, include a \"y\" key in returned dicts for class\n", "                       label. If classes are not available and this is true, an\n", "                       exception will be raised.\n", "    :param deterministic: if True, yield results in a deterministic order.\n", "    :param random_crop: if True, randomly crop the images for augmentation.\n", "    :param random_flip: if True, randomly flip the images for augmentation.\n", "    \"\"\"\n", "    gt_dir = os.path.expanduser(gt_path)\n", "    mask_dir = os.path.expanduser(mask_path)\n", "    gt_paths = _list_image_files_recursively(gt_dir)\n", "    mask_paths = _list_image_files_recursively(mask_dir)\n", "    assert len(gt_paths) == len(mask_paths)\n", "    classes = None\n", "    if class_cond:\n", "        raise NotImplementedError()\n", "    dataset = ImageDatasetInpa(\n", "        image_size,\n", "        gt_paths=gt_paths,\n", "        mask_paths=mask_paths,\n", "        classes=classes,\n", "        shard=0,\n", "        num_shards=1,\n", "        random_crop=random_crop,\n", "        random_flip=random_flip,\n", "        return_dict=return_dict,\n", "        max_len=max_len,\n", "        conf=conf,\n", "        offset=offset\n", "    )\n", "    if deterministic:\n", "        loader = DataLoader(\n", "            dataset, batch_size=batch_size, shuffle=False, num_workers=1, drop_last=drop_last\n", "        )\n", "    else:\n", "        loader = DataLoader(\n", "            dataset, batch_size=batch_size, shuffle=True, num_workers=1, drop_last=drop_last\n", "        )\n", "    if return_dataloader:\n", "        return loader\n", "    else:\n", "        return load_data_yield(loader)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _list_image_files_recursively(data_dir):\n", "    results = []\n", "    for entry in sorted(bf.listdir(data_dir)):\n", "        full_path = bf.join(data_dir, entry)\n", "        ext = entry.split(\".\")[-1]\n", "        if \".\" in entry and ext.lower() in [\"jpg\", \"jpeg\", \"png\", \"gif\"]:\n", "            results.append(full_path)\n", "        elif bf.isdir(full_path):\n", "            results.extend(_list_image_files_recursively(full_path))\n", "    return results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ImageDatasetInpa(Dataset):\n", "    def __init__(\n", "        self,\n", "        resolution,\n", "        gt_paths,\n", "        mask_paths,\n", "        classes=None,\n", "        shard=0,\n", "        num_shards=1,\n", "        random_crop=False,\n", "        random_flip=True,\n", "        return_dict=False,\n", "        max_len=None,\n", "        conf=None,\n", "        offset=0\n", "    ):\n", "        super().__init__()\n", "        self.resolution = resolution\n", "        gt_paths = sorted(gt_paths)[offset:]\n", "        mask_paths = sorted(mask_paths)[offset:]\n", "        self.local_gts = gt_paths[shard:][::num_shards]\n", "        self.local_masks = mask_paths[shard:][::num_shards]\n", "        self.local_classes = None if classes is None else classes[shard:][::num_shards]\n", "        self.random_crop = random_crop\n", "        self.random_flip = random_flip\n", "        self.return_dict = return_dict\n", "        self.max_len = max_len\n", "    def __len__(self):\n", "        if self.max_len is not None:\n", "            return self.max_len\n", "        return len(self.local_gts)\n", "    def __getitem__(self, idx):\n", "        gt_path = self.local_gts[idx]\n", "        pil_gt = self.imread(gt_path)\n", "        mask_path = self.local_masks[idx]\n", "        pil_mask = self.imread(mask_path)\n", "        if self.random_crop:\n", "            raise NotImplementedError()\n", "        else:\n", "            arr_gt = center_crop_arr(pil_gt, self.resolution)\n", "            arr_mask = center_crop_arr(pil_mask, self.resolution)\n", "        if self.random_flip and random.random() < 0.5:\n", "            arr_gt = arr_gt[:, ::-1]\n", "            arr_mask = arr_mask[:, ::-1]\n", "        arr_gt = arr_gt.astype(np.float32) / 127.5 - 1\n", "        arr_mask = arr_mask.astype(np.float32) / 255.0\n", "        out_dict = {}\n", "        if self.local_classes is not None:\n", "            out_dict[\"y\"] = np.array(self.local_classes[idx], dtype=np.int64)\n", "        if self.return_dict:\n", "            name = os.path.basename(gt_path)\n", "            return {\n", "                'GT': np.transpose(arr_gt, [2, 0, 1]),\n", "                'GT_name': name,\n", "                'gt_keep_mask': np.transpose(arr_mask, [2, 0, 1]),\n", "            }\n", "        else:\n", "            raise NotImplementedError()\n", "    def imread(self, path):\n", "        with bf.BlobFile(path, \"rb\") as f:\n", "            pil_image = Image.open(f)\n", "            pil_image.load()\n", "        pil_image = pil_image.convert(\"RGB\")\n", "        return pil_image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def center_crop_arr(pil_image, image_size):\n", "    # We are not on a new enough PIL to support the `reducing_gap`\n", "    # argument, which uses BOX downsampling at powers of two first.\n", "    # Thus, we do it by hand to improve downsample quality.\n", "    while min(*pil_image.size) >= 2 * image_size:\n", "        pil_image = pil_image.resize(\n", "            tuple(x // 2 for x in pil_image.size), resample=Image.BOX\n", "        )\n", "    scale = image_size / min(*pil_image.size)\n", "    pil_image = pil_image.resize(\n", "        tuple(round(x * scale) for x in pil_image.size), resample=Image.BICUBIC\n", "    )\n", "    arr = np.array(pil_image)\n", "    crop_y = (arr.shape[0] - image_size) // 2\n", "    crop_x = (arr.shape[1] - image_size) // 2\n", "    return arr[crop_y: crop_y + image_size, crop_x: crop_x + image_size]"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}