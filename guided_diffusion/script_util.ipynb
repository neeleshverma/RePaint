{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Copyright (c) 2022 Huawei Technologies Co., Ltd.<br>\n", "Licensed under CC BY-NC-SA 4.0 (Attribution-NonCommercial-ShareAlike 4.0 International) (the \"License\");<br>\n", "you may not use this file except in compliance with the License.<br>\n", "You may obtain a copy of the License at<br>\n", "<br>\n", "    https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode<br>\n", "<br>\n", "The code is released for academic research use only. For commercial use, please contact Huawei Technologies Co., Ltd.<br>\n", "Unless required by applicable law or agreed to in writing, software<br>\n", "distributed under the License is distributed on an \"AS IS\" BASIS,<br>\n", "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br>\n", "See the License for the specific language governing permissions and<br>\n", "limitations under the License.<br>\n", "<br>\n", "This repository was forked from https://github.com/openai/guided-diffusion, which is under the MIT license"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import inspect"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from . import gaussian_diffusion as gd\n", "from .respace import SpacedDiffusion, space_timesteps\n", "from .unet import SuperResModel, UNetModel, EncoderUNetModel"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NUM_CLASSES = 1000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def diffusion_defaults():\n", "    \"\"\"\n", "    Defaults for image and classifier training.\n", "    \"\"\"\n", "    return dict(\n", "        learn_sigma=False,\n", "        diffusion_steps=1000,\n", "        noise_schedule=\"linear\",\n", "        timestep_respacing=\"\",\n", "        use_kl=False,\n", "        predict_xstart=False,\n", "        rescale_timesteps=False,\n", "        rescale_learned_sigmas=False,\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def classifier_defaults():\n", "    \"\"\"\n", "    Defaults for classifier models.\n", "    \"\"\"\n", "    return dict(\n", "        image_size=64,\n", "        classifier_use_fp16=False,\n", "        classifier_width=128,\n", "        classifier_depth=2,\n", "        classifier_attention_resolutions=\"32,16,8\",\n", "        classifier_use_scale_shift_norm=True,\n", "        classifier_resblock_updown=True,\n", "        classifier_pool=\"attention\",\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def model_and_diffusion_defaults():\n", "    \"\"\"\n", "    Defaults for image training.\n", "    \"\"\"\n", "    res = dict(\n", "        image_size=64,\n", "        num_channels=128,\n", "        num_res_blocks=2,\n", "        num_heads=4,\n", "        num_heads_upsample=-1,\n", "        num_head_channels=-1,\n", "        attention_resolutions=\"16,8\",\n", "        channel_mult=\"\",\n", "        dropout=0.0,\n", "        class_cond=False,\n", "        use_checkpoint=False,\n", "        use_scale_shift_norm=True,\n", "        resblock_updown=False,\n", "        use_fp16=False,\n", "        use_new_attention_order=False,\n", "    )\n", "    res.update(diffusion_defaults())\n", "    return res"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def classifier_and_diffusion_defaults():\n", "    res = classifier_defaults()\n", "    res.update(diffusion_defaults())\n", "    return res"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_model_and_diffusion(\n", "    image_size,\n", "    class_cond,\n", "    learn_sigma,\n", "    num_channels,\n", "    num_res_blocks,\n", "    channel_mult,\n", "    num_heads,\n", "    num_head_channels,\n", "    num_heads_upsample,\n", "    attention_resolutions,\n", "    dropout,\n", "    diffusion_steps,\n", "    noise_schedule,\n", "    timestep_respacing,\n", "    use_kl,\n", "    predict_xstart,\n", "    rescale_timesteps,\n", "    rescale_learned_sigmas,\n", "    use_checkpoint,\n", "    use_scale_shift_norm,\n", "    resblock_updown,\n", "    use_fp16,\n", "    use_new_attention_order,\n", "    conf=None\n", "):\n", "    model = create_model(\n", "        image_size,\n", "        num_channels,\n", "        num_res_blocks,\n", "        channel_mult=channel_mult,\n", "        learn_sigma=learn_sigma,\n", "        class_cond=class_cond,\n", "        use_checkpoint=use_checkpoint,\n", "        attention_resolutions=attention_resolutions,\n", "        num_heads=num_heads,\n", "        num_head_channels=num_head_channels,\n", "        num_heads_upsample=num_heads_upsample,\n", "        use_scale_shift_norm=use_scale_shift_norm,\n", "        dropout=dropout,\n", "        resblock_updown=resblock_updown,\n", "        use_fp16=use_fp16,\n", "        use_new_attention_order=use_new_attention_order,\n", "        conf=conf\n", "    )\n", "    diffusion = create_gaussian_diffusion(\n", "        steps=diffusion_steps,\n", "        learn_sigma=learn_sigma,\n", "        noise_schedule=noise_schedule,\n", "        use_kl=use_kl,\n", "        predict_xstart=predict_xstart,\n", "        rescale_timesteps=rescale_timesteps,\n", "        rescale_learned_sigmas=rescale_learned_sigmas,\n", "        timestep_respacing=timestep_respacing,\n", "        conf=conf\n", "    )\n", "    return model, diffusion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_model(\n", "    image_size,\n", "    num_channels,\n", "    num_res_blocks,\n", "    channel_mult=\"\",\n", "    learn_sigma=False,\n", "    class_cond=False,\n", "    use_checkpoint=False,\n", "    attention_resolutions=\"16\",\n", "    num_heads=1,\n", "    num_head_channels=-1,\n", "    num_heads_upsample=-1,\n", "    use_scale_shift_norm=False,\n", "    dropout=0,\n", "    resblock_updown=False,\n", "    use_fp16=False,\n", "    use_new_attention_order=False,\n", "    image_size_inference=None,\n", "    conf=None\n", "):\n", "    if channel_mult == \"\":\n", "        if image_size == 512:\n", "            channel_mult = (0.5, 1, 1, 2, 2, 4, 4)\n", "        elif image_size == 256:\n", "            channel_mult = (1, 1, 2, 2, 4, 4)\n", "        elif image_size == 128:\n", "            channel_mult = (1, 1, 2, 3, 4)\n", "        elif image_size == 64:\n", "            channel_mult = (1, 2, 3, 4)\n", "        else:\n", "            raise ValueError(f\"unsupported image size: {image_size}\")\n", "    elif isinstance(channel_mult, tuple):\n", "        pass\n", "    else:\n", "        channel_mult = tuple(int(ch_mult)\n", "                             for ch_mult in channel_mult.split(\",\"))\n", "    attention_ds = []\n", "    for res in attention_resolutions.split(\",\"):\n", "        attention_ds.append(image_size // int(res))\n", "    image_size_inference = image_size_inference or image_size\n", "    return UNetModel(\n", "        image_size=image_size,\n", "        in_channels=3,\n", "        model_channels=num_channels,\n", "        out_channels=(3 if not learn_sigma else 6),\n", "        num_res_blocks=num_res_blocks,\n", "        attention_resolutions=tuple(attention_ds),\n", "        dropout=dropout,\n", "        channel_mult=channel_mult,\n", "        num_classes=(NUM_CLASSES if class_cond else None),\n", "        use_checkpoint=use_checkpoint,\n", "        use_fp16=use_fp16,\n", "        num_heads=num_heads,\n", "        num_head_channels=num_head_channels,\n", "        num_heads_upsample=num_heads_upsample,\n", "        use_scale_shift_norm=use_scale_shift_norm,\n", "        resblock_updown=resblock_updown,\n", "        use_new_attention_order=use_new_attention_order,\n", "        conf=conf\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_classifier(\n", "    image_size,\n", "    classifier_use_fp16,\n", "    classifier_width,\n", "    classifier_depth,\n", "    classifier_attention_resolutions,\n", "    classifier_use_scale_shift_norm,\n", "    classifier_resblock_updown,\n", "    classifier_pool,\n", "    image_size_inference=None\n", "):\n", "    if image_size == 512:\n", "        channel_mult = (0.5, 1, 1, 2, 2, 4, 4)\n", "    elif image_size == 256:\n", "        channel_mult = (1, 1, 2, 2, 4, 4)\n", "    elif image_size == 128:\n", "        channel_mult = (1, 1, 2, 3, 4)\n", "    elif image_size == 64:\n", "        channel_mult = (1, 2, 3, 4)\n", "    else:\n", "        raise ValueError(f\"unsupported image size: {image_size}\")\n", "    attention_ds = []\n", "    for res in classifier_attention_resolutions.split(\",\"):\n", "        attention_ds.append(image_size // int(res))\n", "    image_size_inference = image_size_inference or image_size\n", "    return EncoderUNetModel(\n", "        image_size=image_size_inference,\n", "        in_channels=3,\n", "        model_channels=classifier_width,\n", "        out_channels=1000,\n", "        num_res_blocks=classifier_depth,\n", "        attention_resolutions=tuple(attention_ds),\n", "        channel_mult=channel_mult,\n", "        use_fp16=classifier_use_fp16,\n", "        num_head_channels=64,\n", "        use_scale_shift_norm=classifier_use_scale_shift_norm,\n", "        resblock_updown=classifier_resblock_updown,\n", "        pool=classifier_pool,\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_gaussian_diffusion(\n", "    *,\n", "    steps=1000,\n", "    learn_sigma=False,\n", "    sigma_small=False,\n", "    noise_schedule=\"linear\",\n", "    use_kl=False,\n", "    predict_xstart=False,\n", "    rescale_timesteps=False,\n", "    rescale_learned_sigmas=False,\n", "    timestep_respacing=\"\",\n", "    conf=None\n", "):\n", "    betas = gd.get_named_beta_schedule(noise_schedule, steps, use_scale=True)\n", "    if conf.use_value_logger:\n", "        conf.value_logger.add_value(\n", "            betas, 'betas create_gaussian_diffusion')\n", "    if use_kl:\n", "        loss_type = gd.LossType.RESCALED_KL\n", "    elif rescale_learned_sigmas:\n", "        loss_type = gd.LossType.RESCALED_MSE\n", "    else:\n", "        loss_type = gd.LossType.MSE\n", "    if not timestep_respacing:\n", "        timestep_respacing = [steps]\n", "    return SpacedDiffusion(\n", "        use_timesteps=space_timesteps(steps, timestep_respacing),\n", "        betas=betas,\n", "        model_mean_type=(\n", "            gd.ModelMeanType.EPSILON if not predict_xstart else gd.ModelMeanType.START_X\n", "        ),\n", "        model_var_type=(\n", "            (\n", "                gd.ModelVarType.FIXED_LARGE\n", "                if not sigma_small\n", "                else gd.ModelVarType.FIXED_SMALL\n", "            )\n", "            if not learn_sigma\n", "            else gd.ModelVarType.LEARNED_RANGE\n", "        ),\n", "        loss_type=loss_type,\n", "        rescale_timesteps=rescale_timesteps,\n", "        conf=conf\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def select_args(args_dict, keys):\n", "    return {k: args_dict[k] for k in keys}"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}